{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keras 2.0.6 + TensorFlow 1.2.1 GPU\n",
    "# train part\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "random.seed(42)\n",
    "original_size = 500\n",
    "SIZE = 512\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def double_conv_layer(x, size, dropout, batch_norm):\n",
    "    axis=1\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    \n",
    "    if batch_norm == True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "        \n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    \n",
    "    if batch_norm == True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "        \n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "        \n",
    "    return conv\n",
    "\n",
    "def define_model():\n",
    "    dropout_val = 0\n",
    "    batch_norm = True\n",
    "    \n",
    "    inputs = Input((3, SIZE, SIZE))\n",
    "    axis=1\n",
    "        \n",
    "    conv1 = double_conv_layer(inputs, 32, dropout_val, batch_norm)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = double_conv_layer(pool1, 64, dropout_val, batch_norm)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = double_conv_layer(pool2, 128, dropout_val, batch_norm)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = double_conv_layer(pool3, 256, dropout_val, batch_norm)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = double_conv_layer(pool4, 512, dropout_val, batch_norm)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    conv6 = double_conv_layer(pool5, 1024, dropout_val, batch_norm)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv5], axis=axis)\n",
    "    conv7 = double_conv_layer(up6, 512, dropout_val, batch_norm)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv4], axis=axis)\n",
    "    conv8 = double_conv_layer(up7, 256, dropout_val, batch_norm)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv3], axis=axis)\n",
    "    conv9 = double_conv_layer(up8, 128, dropout_val, batch_norm)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv9), conv2], axis=axis)\n",
    "    conv10 = double_conv_layer(up9, 64, dropout_val, batch_norm)\n",
    "    \n",
    "    up10 = concatenate([UpSampling2D(size=(2, 2))(conv10), conv1], axis=axis)\n",
    "    conv11 = double_conv_layer(up10, 32, 0, batch_norm)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1))(conv11)\n",
    "    conv12 = BatchNormalization(axis=axis)(conv12)\n",
    "    conv12 = Activation('sigmoid')(conv12)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv12)\n",
    "    return model\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def elastic_transform(img, mask, alpha, sigma, random_state=None):\n",
    "    from scipy.ndimage.interpolation import map_coordinates\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = (img.shape[0], img.shape[1])\n",
    "    \n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "   \n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1))\n",
    "    \n",
    "    res_img = np.zeros_like(img)\n",
    "    res_mask = np.zeros_like(mask)\n",
    "\n",
    "    \n",
    "    for i in range(res_img.shape[2]):\n",
    "        res_img[:,:,i] = map_coordinates(img[:,:,i], indices, order=1).reshape(shape)\n",
    "        res_img[:,:,i] = cv2.convertScaleAbs(res_img[:,:,i])  \n",
    "        \n",
    "    res_mask = map_coordinates(mask, indices, order=1).reshape(shape)\n",
    "    \n",
    "    return res_img, res_mask\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def subimage(image, center, theta):\n",
    "    from math import cos, sin\n",
    "    \n",
    "    width, height = SIZE, SIZE\n",
    "    \n",
    "    theta *= 3.14159 / 180\n",
    "\n",
    "    v_x = (cos(theta), sin(theta))\n",
    "    v_y = (-sin(theta), cos(theta))\n",
    "    s_x = center[0] - v_x[0] * (width / 2) - v_y[0] * (height / 2)\n",
    "    s_y = center[1] - v_x[1] * (width / 2) - v_y[1] * (height / 2)\n",
    "\n",
    "    mapping = np.array([[v_x[0],v_y[0], s_x],\n",
    "                        [v_x[1],v_y[1], s_y]])\n",
    "\n",
    "    return cv2.warpAffine(image,mapping,(width, height),flags=cv2.WARP_INVERSE_MAP,borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "\n",
    "train_list = glob.glob('/data/PathImageSegmentation-data/training/images/*.tif')\n",
    "train_list = sorted(train_list, key=lambda k: random.random())\n",
    "mask_list = [s.replace('images/','truth/').replace('.tif','_mask.png') for s in train_list]\n",
    "\n",
    "# load images into RAM (elastic_transform is too slow)\n",
    "\n",
    "X_imgs = []\n",
    "Y_masks = []\n",
    "X_eimgs = []\n",
    "Y_emasks = []\n",
    "bordersize = 6\n",
    "\n",
    "for iter_ in range(len(train_list)):\n",
    "\n",
    "    print (iter_)\n",
    "\n",
    "    img = cv2.imread(train_list[iter_]).astype(np.float32)\n",
    "    img=cv2.copyMakeBorder(img, top=bordersize, bottom=bordersize, left=bordersize, right=bordersize,\n",
    "                           borderType= cv2.BORDER_CONSTANT)\n",
    "\n",
    "    mask = cv2.imread(mask_list[iter_], 0).astype(np.float32)\n",
    "    mask /= 255.0\n",
    "\n",
    "    mask=cv2.copyMakeBorder(mask, top=bordersize, bottom=bordersize, left=bordersize, right=bordersize,\n",
    "                           borderType= cv2.BORDER_CONSTANT)\n",
    "\n",
    "    for iter2_ in range(0, 3):\n",
    "\n",
    "        coef_sigma = random.randint(5, 8) * 0.1\n",
    "        eimg, emask = elastic_transform(img, 255 * mask, mask.shape[1] * 10,\n",
    "                                          mask.shape[1] * coef_sigma)\n",
    "\n",
    "        eimg /= 255.0\n",
    "        eimg -= 0.5\n",
    "\n",
    "        emask[emask < 100] = 0.\n",
    "        emask[emask >= 100] = 1.\n",
    "\n",
    "        X_eimgs.append(eimg)\n",
    "        Y_emasks.append(emask)\n",
    "\n",
    "    img /= 255.0\n",
    "    img -= 0.5\n",
    "\n",
    "    X_imgs.append(img)\n",
    "    Y_masks.append(mask)\n",
    "        \n",
    "def generate_data(b_size):\n",
    "    while True:\n",
    "    \n",
    "        imgs = []\n",
    "        masks = []\n",
    "        \n",
    "        for s in range(b_size):\n",
    "                        \n",
    "            if np.random.random() < 0.5:\n",
    "                i = random.randint(0, len(train_list) - 1)\n",
    "\n",
    "                tmp_img = X_imgs[i]\n",
    "                tmp_mask = Y_masks[i]\n",
    "            else:\n",
    "                i = random.randint(0, len(X_eimgs) - 1)\n",
    "                \n",
    "                tmp_img = X_eimgs[i]\n",
    "                tmp_mask = Y_emasks[i]\n",
    "                \n",
    "            if np.random.random() < 0.5:     \n",
    "                gamma = random.randint(5, 20) * 0.1\n",
    "                tmp_img = adjust_gamma(((tmp_img+0.5) * 255).astype(np.uint8), gamma).astype(np.float32)\n",
    "                tmp_img /= 255.0\n",
    "                tmp_img -= 0.5\n",
    "            \n",
    "            if np.random.random() < 0.5:\n",
    "                \n",
    "                tmp_img = cv2.flip(tmp_img, 0)\n",
    "                tmp_mask = cv2.flip(tmp_mask,0)\n",
    "                \n",
    "            if np.random.random() < 0.5:\n",
    "                \n",
    "                tmp_img = cv2.flip(tmp_img, 1)\n",
    "                tmp_mask = cv2.flip(tmp_mask,1)\n",
    "                \n",
    "            if np.random.random() < 0.5:\n",
    "                \n",
    "                tmp_img = tmp_img.swapaxes(0, 1)\n",
    "                tmp_mask = tmp_mask.swapaxes(0, 1)\n",
    "            \n",
    "            tmp_mask = tmp_mask[np.newaxis,:,:]\n",
    "            imgs.append(tmp_img)\n",
    "            masks.append(tmp_mask)\n",
    "        \n",
    "        imgs = np.asarray(imgs)\n",
    "        masks = np.asarray(masks)\n",
    "        imgs = np.rollaxis(imgs, 3, 1)\n",
    "            \n",
    "        yield (imgs, masks)\n",
    "            \n",
    "model = define_model()\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, verbose=0),\n",
    "        ModelCheckpoint('unet_512_tmp.hdf5', monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "b_size = 4\n",
    "\n",
    "history = model.fit_generator(generator=generate_data(b_size), steps_per_epoch=200, epochs=200,\n",
    "                   max_queue_size=10, verbose=1, callbacks=callbacks, validation_steps=50,\n",
    "                   validation_data=generate_data(b_size))\n",
    "\n",
    "model.save_weights('unet_512.hdf5')\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).to_csv('unet_512_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict part\n",
    "\n",
    "model = define_model()\n",
    "model.load_weights('unet_815LB.hdf5')\n",
    "\n",
    "from skimage.filters import threshold_yen\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "def filter_by_size(mask, threshold_size):\n",
    "    label_im, nb_labels = ndimage.label(mask)\n",
    "    sizes = ndimage.sum(mask, label_im, range(nb_labels + 1))\n",
    "    mask_size = sizes < threshold_size\n",
    "    remove_pixel = mask_size[label_im]\n",
    "    mask[remove_pixel] = 0\n",
    "    \n",
    "    return mask\n",
    "         \n",
    "def get_mask(img, model):\n",
    "    x = []\n",
    "    x.append(img)\n",
    "    x = np.asarray(x)\n",
    "    x = np.rollaxis(x, 3, 1)\n",
    "    \n",
    "    y = model.predict(x)\n",
    "    \n",
    "    mask = y[0][0]\n",
    "    mask = mask[6:506,6:506]\n",
    "    \n",
    "    thresh = threshold_yen(mask)\n",
    "    \n",
    "    mask[mask > thresh] = 1\n",
    "    mask[mask <= thresh] = 0\n",
    "    \n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "def union_mask(m):\n",
    "    #voting\n",
    "    res = np.zeros_like(m[0])\n",
    "    \n",
    "    for i in range(m[0].shape[0]):\n",
    "        for j in range(m[1].shape[0]):\n",
    "            \n",
    "            count = 0\n",
    "            for idx in range(len(m)):\n",
    "                count += m[idx][i][j]\n",
    "                \n",
    "            if count > 1:\n",
    "                res[i][j] = 1.0\n",
    "                \n",
    "    return res\n",
    "\n",
    "def pred_mask(img, model):\n",
    "    img /= 255.0\n",
    "    img -= 0.5\n",
    "    bordersize = 6\n",
    "    img = cv2.copyMakeBorder(img, top=bordersize, bottom=bordersize, left=bordersize, right=bordersize,\n",
    "                       borderType= cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    mask1 = get_mask(img, model)\n",
    "    img2 = cv2.flip(img, 1)\n",
    "    img3 = cv2.flip(img, 0)\n",
    "    img4 = img.swapaxes(0, 1)\n",
    "    \n",
    "    mask2 = get_mask(img2, model)\n",
    "    mask3 = get_mask(img3, model) \n",
    "    mask4 = get_mask(img4, model)\n",
    "   \n",
    "    mask2 = cv2.flip(mask2, 1)\n",
    "    mask3 = cv2.flip(mask3, 0)\n",
    "    mask4 = mask4.swapaxes(0, 1)\n",
    "    \n",
    "    m = []\n",
    "    m.append(mask1)\n",
    "    m.append(mask2)\n",
    "    m.append(mask3)\n",
    "    m.append(mask4)\n",
    "    mask_u = union_mask(m)\n",
    "    \n",
    "    mask_u = morphology.remove_small_holes(mask_u, 600).astype(np.uint8)\n",
    "    mask_u = filter_by_size(mask_u, 50).astype(np.uint8)\n",
    "        \n",
    "    return mask_u\n",
    "\n",
    "def write_to_txt(path, mask):\n",
    "    with open(path, 'w') as out:\n",
    "        for x in range(500):\n",
    "            for y in range(500):\n",
    "                out.write(str(int(mask[y, x])))\n",
    "            out.write('\\n')\n",
    "    \n",
    "def write_submission():\n",
    "    test_list = glob.glob('/data/PathImageSegmentation-data/testing/images/*.tif')\n",
    "    \n",
    "    for i in tqdm(range(len(test_list))):\n",
    "                \n",
    "        img = cv2.imread(test_list[i]).astype(np.float32)\n",
    "                      \n",
    "        mask_u = pred_mask(img.copy(), model)\n",
    "        \n",
    "        mask_path = test_list[i].replace('/data/PathImageSegmentation-data/testing/images/','')\n",
    "        mask_path = mask_path.replace('.tif','_mask.txt')\n",
    "        \n",
    "        write_to_txt('1/' + mask_path, mask_u)\n",
    "        \n",
    "        \n",
    "write_submission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
